{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Shark tank Evaluator-optimizer\n",
        "\n",
        "In the evaluator-optimizer workflow, one LLM call generates a response while another provides evaluation and feedback in a loop.\n",
        "\n",
        "When to use this workflow: This workflow is particularly effective when we have clear evaluation criteria, and when iterative refinement provides measurable value. The two signs of good fit are, first, that LLM responses can be demonstrably improved when a human articulates their feedback; and second, that the LLM can provide such feedback. This is analogous to the iterative writing process a human writer might go through when producing a polished document.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"]=\"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\"\n",
        "# os.environ[\"GROQ_API_KEY\"]=os.getenv(\"GROQ_API_KEY\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# llm=ChatGroq(model=\"qwen-2.5-32b\")\n",
        "llm = ChatOpenAI(model=\"gpt-4o\")\n",
        "result=llm.invoke(\"Hello Agent Ai\")\n",
        "result\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from typing_extensions import Literal,TypedDict\n",
        "from pydantic import BaseModel, Field\n",
        "from langchain_core.messages import HumanMessage, SystemMessage\n",
        "from IPython.display import Image,display\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Graph state\n",
        "\n",
        "class State(TypedDict):\n",
        "    pitch:str\n",
        "    product:str\n",
        "    judge_feedback:str \n",
        "    pitch_good_or_not:str \n",
        "\n",
        "# Schema for structured output to use in evaluation\n",
        "class Feedback(BaseModel):\n",
        "    grade:Literal[\"good pitch\",\"not good pitch\"]=Field(description=\"Decide product pitch is good for investment by shark tank judge\"),\n",
        "    feedback:str=Field(\n",
        "        description=\"If the pitch is not investable in current AI market ,provide feedback on how to make product AI marker fit\"\n",
        "    )\n",
        "\n",
        "# Augment the LLM with schema for structured output\n",
        "\n",
        "evaluator=llm.with_structured_output(Feedback)\n",
        "\n",
        "#Nodes \n",
        "\n",
        "def llm_call_pitch_generator(state:State):\n",
        "    \"\"\" LLM generates a pitch based on the topic\"\"\"\n",
        "    if state.get(\"judge_feedback\"):\n",
        "        msg=llm.invoke(\n",
        "            f\"Write a investment pitch for the {state['product']} but take into account the judge feedback:{state['judge_feedback']}\"\n",
        "        )\n",
        "    else:\n",
        "        msg=llm.invoke(f\"Write a investment pitch about {state['product']}\")\n",
        "    return {\"pitch\":msg.content}\n",
        "\n",
        "#Nodes \n",
        "def llm_shark_tank_judge_pitch_evaluator(state:State):\n",
        "    \"\"\"LLM evaluate the pitch as a shark tank judge\"\"\"\n",
        "    grade=evaluator.invoke(f\"Grade the pitch for {state['product']}: {state['pitch']}\")\n",
        "    return {\"pitch_good_or_not\":grade.grade,\"judge_feedback\":grade.feedback}\n",
        "\n",
        "\n",
        "# Conditional edge function to route back to pitch generator or end based upon feedback from the evaluator\n",
        "\n",
        "def route_pitch(state:State):\n",
        "    \"\"\"Route back to pitch generator or end based on upon the feedback from shark tank judge evaluator\"\"\"\n",
        "    if state[\"pitch_good_or_not\"]==\"good pitch\":\n",
        "        return \"Accepted\"\n",
        "    elif state[\"pitch_good_or_not\"]==\"not good pitch\":\n",
        "        return \"Rejected +Feedback\"\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Build workflow\n",
        "from langgraph.graph import StateGraph,START,END\n",
        "shark_tank_builder=StateGraph(State)\n",
        "\n",
        "#Add the nodes\n",
        "shark_tank_builder.add_node(\"llm_call_pitch_generator\",llm_call_pitch_generator)\n",
        "shark_tank_builder.add_node(\"llm_shark_tank_judge_pitch_evaluator\",llm_shark_tank_judge_pitch_evaluator)\n",
        "\n",
        "#Add edges to connect nodes \n",
        "shark_tank_builder.add_edge(START,\"llm_call_pitch_generator\")\n",
        "shark_tank_builder.add_edge(\"llm_call_pitch_generator\",\"llm_shark_tank_judge_pitch_evaluator\")\n",
        "\n",
        "shark_tank_builder.add_conditional_edges(\n",
        "    \"llm_shark_tank_judge_pitch_evaluator\",\n",
        "    route_pitch,{\n",
        "        # Name returned by route_joke:NAME OF NEXT NODE TO VISIT\n",
        "        \"Accepted\":END,\n",
        "        \"Rejected +Feedback\":\"llm_call_pitch_generator\"\n",
        "    },\n",
        ")\n",
        "\n",
        "#Compile the workflow\n",
        "shark_tank_workflow=shark_tank_builder.compile()\n",
        "\n",
        "#show the workflow\n",
        "\n",
        "display(Image(shark_tank_workflow.get_graph().draw_mermaid_png()))\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VH-pBizvFm9O"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Invoke\n",
        "\n",
        "state=shark_tank_workflow.invoke({\"product\":\"AI Image generator\"})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(state[\"pitch\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V_wVt_lfFm9P"
      },
      "outputs": [],
      "source": [
        "print(state[\"judge_feedback\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(state['pitch_good_or_not'])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
